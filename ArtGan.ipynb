{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ArtGan.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOEA6uC033189YqiBPPYfIs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devanshugupta/AbstractArt_GAN/blob/main/ArtGan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bUZb7Lk_QRR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6rciqGdF-Z8",
        "outputId": "4232d96e-e76a-46ed-b78e-1b581d34f265"
      },
      "source": [
        "#!wget web.fsktm.um.edu.my/~cschan/source/ICIP2017/wikiart.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-18 17:17:00--  http://web.fsktm.um.edu.my/~cschan/source/ICIP2017/wikiart.zip\n",
            "Resolving web.fsktm.um.edu.my (web.fsktm.um.edu.my)... 103.18.2.145\n",
            "Connecting to web.fsktm.um.edu.my (web.fsktm.um.edu.my)|103.18.2.145|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27301958850 (25G) [application/zip]\n",
            "Saving to: ‘wikiart.zip’\n",
            "\n",
            "wikiart.zip         100%[===================>]  25.43G  7.48MB/s    in 61m 19s \n",
            "\n",
            "2021-02-18 18:18:19 (7.08 MB/s) - ‘wikiart.zip’ saved [27301958850/27301958850]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eao-fD9lLXZL"
      },
      "source": [
        "#!unzip wikiart.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhMKzXbBZ21B",
        "outputId": "29736015-ee53-4b2d-efb6-f2b9620d268f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5bmt1EXafsd"
      },
      "source": [
        "#!cp -r /content/wikiart/Cubism /content/drive/MyDrive/dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urCcS_PZhv0O",
        "outputId": "c2aebb77-906a-4236-cc45-062fe8973d40"
      },
      "source": [
        "!ls /content/drive/MyDrive/wikiart/High_Renaissance | wc -l\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmXOf0qt6avU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e442459-0502-4afd-f26c-c40fea392021"
      },
      "source": [
        "## image_resizer.py\r\n",
        "# Importing required libraries\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "# Defining an image size and image channel\r\n",
        "# We are going to resize all our images to 128X128 size and since our images are colored images\r\n",
        "# We are setting our image channels to 3 (RGB)\r\n",
        "\r\n",
        "IMAGE_SIZE = 128\r\n",
        "IMAGE_CHANNELS = 3\r\n",
        "IMAGE_DIR = '/content/drive/MyDrive/wikiart/Minimalism'\r\n",
        "# Defining image dir path. Change this if you have different directory\r\n",
        "images_path = IMAGE_DIR \r\n",
        "\r\n",
        "training_data = []\r\n",
        "print('resizing...')\r\n",
        "\r\n",
        "for file in [,'/content/drive/MyDrive/wikiart/Cubism','/content/drive/MyDrive/wikiart/High_Renaissance']:\r\n",
        "    count=0\r\n",
        "    for filename in os.listdir(file):\r\n",
        "        path = os.path.join(file, filename)\r\n",
        "        image = Image.open(path).resize((IMAGE_SIZE, IMAGE_SIZE), Image.ANTIALIAS)\r\n",
        "\r\n",
        "        training_data.append(np.asarray(image))\r\n",
        "        count+=1\r\n",
        "        print(count,end=',')\r\n",
        "    print('')\r\n",
        "training_data = np.reshape(\r\n",
        "    training_data, (-1, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS))\r\n",
        "training_data = training_data / 127.5 - 1\r\n",
        "    \r\n",
        "print('saving file...')\r\n",
        "np.save('MCH_data.npy', training_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "resizing...\n",
            "1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,\n",
            "1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,\n",
            "1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,\n",
            "saving file...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY9SB5hgF-Bl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fExR6FeZG7Mb"
      },
      "source": [
        "!cp -r /content/MCH_data.npy /content/drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEejluMP899S"
      },
      "source": [
        "from keras.layers import Input, Reshape, Dropout, Dense, Flatten, BatchNormalization, Activation, ZeroPadding2D\r\n",
        "from keras.layers.advanced_activations import LeakyReLU\r\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\r\n",
        "from keras.models import Sequential, Model, load_model\r\n",
        "from keras.optimizers import Adam\r\n",
        "import numpy as np\r\n",
        "from PIL import Image\r\n",
        "import os\r\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqG7R5W-89-a"
      },
      "source": [
        "# Preview image Frame\r\n",
        "PREVIEW_ROWS = 4\r\n",
        "PREVIEW_COLS = 7\r\n",
        "PREVIEW_MARGIN = 4\r\n",
        "SAVE_FREQ = 100\r\n",
        "# Size vector to generate images from\r\n",
        "NOISE_SIZE = 100\r\n",
        "# Configuration\r\n",
        "EPOCHS = 10000 # number of iterations\r\n",
        "BATCH_SIZE = 32\r\n",
        "GENERATE_RES = 3\r\n",
        "IMAGE_SIZE = 128 # rows/cols\r\n",
        "IMAGE_CHANNELS = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35b4MQGp8-Bw"
      },
      "source": [
        "training_data = np.load('/content/drive/MyDrive/MCH_data.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okE5fo-VLSVI",
        "outputId": "7e046766-c60b-4981-de56-a67c3c91960a"
      },
      "source": [
        "training_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4915, 128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_iRMyBr9Vrp"
      },
      "source": [
        "def build_discriminator(image_shape):\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Conv2D(32, kernel_size=3, strides=2,input_shape=image_shape, padding='same'))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))\r\n",
        "    model.add(Dropout(0.25))\r\n",
        "    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same'))\r\n",
        "    model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\r\n",
        "    model.add(BatchNormalization(momentum=0.8))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))\r\n",
        "    model.add(Dropout(0.25))\r\n",
        "    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\r\n",
        "    model.add(BatchNormalization(momentum=0.8))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))\r\n",
        "    model.add(Dropout(0.25))\r\n",
        "    model.add(Conv2D(256, kernel_size=3, strides=1, padding='same'))\r\n",
        "    model.add(BatchNormalization(momentum=0.8))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))\r\n",
        "    model.add(Dropout(0.25))\r\n",
        "    model.add(Conv2D(512, kernel_size=3, strides=1, padding='same'))\r\n",
        "    model.add(BatchNormalization(momentum=0.8))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))\r\n",
        "    model.add(Dropout(0.25))\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(1, activation='sigmoid'))\r\n",
        "    input_image = Input(shape=image_shape)\r\n",
        "    validity = model(input_image)\r\n",
        "    return Model(input_image, validity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypM3p4Cl9i6D"
      },
      "source": [
        "def build_generator(noise_size, channels):\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Dense(4 * 4 * 256, activation='relu', input_dim=noise_size))\r\n",
        "    model.add(Reshape((4, 4, 256)))\r\n",
        "    model.add(UpSampling2D())\r\n",
        "    model.add(Conv2D(256, kernel_size=3, padding='same'))\r\n",
        "    model.add(BatchNormalization(momentum=0.8))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(UpSampling2D())\r\n",
        "    model.add(Conv2D(256, kernel_size=3, padding='same'))\r\n",
        "    model.add(BatchNormalization(momentum=0.8))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    for i in range(GENERATE_RES):\r\n",
        "        model.add(UpSampling2D())\r\n",
        "        model.add(Conv2D(256, kernel_size=3, padding='same'))\r\n",
        "        model.add(BatchNormalization(momentum=0.8))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "    model.summary()\r\n",
        "    model.add(Conv2D(channels, kernel_size=3, padding='same'))\r\n",
        "    model.add(Activation('tanh'))\r\n",
        "    input = Input(shape=(noise_size,))\r\n",
        "    generated_image = model(input)\r\n",
        "    \r\n",
        "    return Model(input, generated_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whHMDxOZ92_e"
      },
      "source": [
        "def save_images(cnt, noise):\r\n",
        "    image_array = np.full((PREVIEW_MARGIN + (PREVIEW_ROWS * (IMAGE_SIZE + PREVIEW_MARGIN)),\r\n",
        "        PREVIEW_MARGIN + (PREVIEW_COLS * (IMAGE_SIZE + PREVIEW_MARGIN)), 3),\r\n",
        "        255, dtype=np.uint8)\r\n",
        "    generated_images = generator.predict(noise)\r\n",
        "    generated_images = 0.5 * generated_images + 0.5\r\n",
        "    image_count = 0\r\n",
        "    for row in range(PREVIEW_ROWS):\r\n",
        "        for col in range(PREVIEW_COLS):\r\n",
        "            r = row * (IMAGE_SIZE + PREVIEW_MARGIN) + PREVIEW_MARGIN\r\n",
        "            c = col * (IMAGE_SIZE + PREVIEW_MARGIN) + PREVIEW_MARGIN\r\n",
        "            image_array[r:r + IMAGE_SIZE, c:c +\r\n",
        "                        IMAGE_SIZE] = generated_images[image_count] * 255\r\n",
        "            image_count += 1\r\n",
        "    output_path = 'outputAll'\r\n",
        "    if not os.path.exists(output_path):\r\n",
        "        os.makedirs(output_path)\r\n",
        "    filename = os.path.join(output_path, f\"trained-{cnt}.png\")\r\n",
        "    im = Image.fromarray(image_array)\r\n",
        "    im.save(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n8ti1zM-Are",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7538e1cd-9ea6-499e-bb9a-13d016080cbf"
      },
      "source": [
        "image_shape = (IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)\r\n",
        "optimizer = Adam(1.5e-4, 0.5)\r\n",
        "discriminator = build_discriminator(image_shape)\r\n",
        "discriminator.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\r\n",
        "generator = build_generator(NOISE_SIZE, IMAGE_CHANNELS)\r\n",
        "random_input = Input(shape=(NOISE_SIZE,))\r\n",
        "generated_image = generator(random_input)\r\n",
        "discriminator.trainable = False\r\n",
        "validity = discriminator(generated_image)\r\n",
        "combined = Model(random_input, validity)\r\n",
        "combined.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\r\n",
        "y_real = np.ones((BATCH_SIZE, 1))\r\n",
        "y_fake = np.zeros((BATCH_SIZE, 1))\r\n",
        "fixed_noise = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, NOISE_SIZE))\r\n",
        "cnt = 1\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "    idx = np.random.randint(0, training_data.shape[0], BATCH_SIZE)\r\n",
        "    x_real = training_data[idx]\r\n",
        "    \r\n",
        "    noise= np.random.normal(0, 1, (BATCH_SIZE, NOISE_SIZE))\r\n",
        "    x_fake = generator.predict(noise)\r\n",
        "    discriminator_metric_real = discriminator.train_on_batch(x_real, y_real)\r\n",
        "    discriminator_metric_generated = discriminator.train_on_batch(x_fake, y_fake)\r\n",
        "    \r\n",
        "    discriminator_metric = 0.5 * np.add(discriminator_metric_real, discriminator_metric_generated)\r\n",
        "    \r\n",
        "    generator_metric = combined.train_on_batch(noise, y_real)\r\n",
        "    if epoch % SAVE_FREQ == 0:\r\n",
        "        save_images(cnt, fixed_noise)\r\n",
        "        cnt += 1\r\n",
        "        print(epoch,'epoch', 'Discriminator accuracy:', 100*  discriminator_metric[1], \r\n",
        "        'Generator accuracy:', 100 * generator_metric[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_13 (Dense)             (None, 4096)              413696    \n",
            "_________________________________________________________________\n",
            "reshape_6 (Reshape)          (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_34 (UpSampling (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_75 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_62 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_40 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_35 (UpSampling (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_76 (Conv2D)           (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_63 (Batc (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_41 (Activation)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_36 (UpSampling (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_77 (Conv2D)           (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_64 (Batc (None, 32, 32, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_42 (Activation)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_37 (UpSampling (None, 64, 64, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_78 (Conv2D)           (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_65 (Batc (None, 64, 64, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_43 (Activation)   (None, 64, 64, 256)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_38 (UpSampling (None, 128, 128, 256)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_79 (Conv2D)           (None, 128, 128, 256)     590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_66 (Batc (None, 128, 128, 256)     1024      \n",
            "_________________________________________________________________\n",
            "activation_44 (Activation)   (None, 128, 128, 256)     0         \n",
            "=================================================================\n",
            "Total params: 3,369,216\n",
            "Trainable params: 3,366,656\n",
            "Non-trainable params: 2,560\n",
            "_________________________________________________________________\n",
            "0 epoch Discriminator accuracy: 26.5625 Generator accuracy: 100.0\n",
            "100 epoch Discriminator accuracy: 18.75 Generator accuracy: 28.125\n",
            "200 epoch Discriminator accuracy: 18.75 Generator accuracy: 65.625\n",
            "300 epoch Discriminator accuracy: 70.3125 Generator accuracy: 96.875\n",
            "400 epoch Discriminator accuracy: 64.0625 Generator accuracy: 56.25\n",
            "500 epoch Discriminator accuracy: 32.8125 Generator accuracy: 46.875\n",
            "600 epoch Discriminator accuracy: 42.1875 Generator accuracy: 56.25\n",
            "700 epoch Discriminator accuracy: 39.0625 Generator accuracy: 59.375\n",
            "800 epoch Discriminator accuracy: 50.0 Generator accuracy: 56.25\n",
            "900 epoch Discriminator accuracy: 42.1875 Generator accuracy: 50.0\n",
            "1000 epoch Discriminator accuracy: 46.875 Generator accuracy: 50.0\n",
            "1100 epoch Discriminator accuracy: 50.0 Generator accuracy: 37.5\n",
            "1200 epoch Discriminator accuracy: 53.125 Generator accuracy: 25.0\n",
            "1300 epoch Discriminator accuracy: 40.625 Generator accuracy: 6.25\n",
            "1400 epoch Discriminator accuracy: 46.875 Generator accuracy: 50.0\n",
            "1500 epoch Discriminator accuracy: 39.0625 Generator accuracy: 18.75\n",
            "1600 epoch Discriminator accuracy: 48.4375 Generator accuracy: 90.625\n",
            "1700 epoch Discriminator accuracy: 50.0 Generator accuracy: 87.5\n",
            "1800 epoch Discriminator accuracy: 48.4375 Generator accuracy: 78.125\n",
            "1900 epoch Discriminator accuracy: 45.3125 Generator accuracy: 78.125\n",
            "2000 epoch Discriminator accuracy: 50.0 Generator accuracy: 100.0\n",
            "2100 epoch Discriminator accuracy: 50.0 Generator accuracy: 96.875\n",
            "2200 epoch Discriminator accuracy: 46.875 Generator accuracy: 87.5\n",
            "2300 epoch Discriminator accuracy: 48.4375 Generator accuracy: 93.75\n",
            "2400 epoch Discriminator accuracy: 50.0 Generator accuracy: 84.375\n",
            "2500 epoch Discriminator accuracy: 51.5625 Generator accuracy: 84.375\n",
            "2600 epoch Discriminator accuracy: 45.3125 Generator accuracy: 87.5\n",
            "2700 epoch Discriminator accuracy: 62.5 Generator accuracy: 81.25\n",
            "2800 epoch Discriminator accuracy: 50.0 Generator accuracy: 62.5\n",
            "2900 epoch Discriminator accuracy: 48.4375 Generator accuracy: 71.875\n",
            "3000 epoch Discriminator accuracy: 89.0625 Generator accuracy: 93.75\n",
            "3100 epoch Discriminator accuracy: 45.3125 Generator accuracy: 100.0\n",
            "3200 epoch Discriminator accuracy: 39.0625 Generator accuracy: 87.5\n",
            "3300 epoch Discriminator accuracy: 50.0 Generator accuracy: 93.75\n",
            "3400 epoch Discriminator accuracy: 51.5625 Generator accuracy: 90.625\n",
            "3500 epoch Discriminator accuracy: 46.875 Generator accuracy: 87.5\n",
            "3600 epoch Discriminator accuracy: 51.5625 Generator accuracy: 87.5\n",
            "3700 epoch Discriminator accuracy: 50.0 Generator accuracy: 93.75\n",
            "3800 epoch Discriminator accuracy: 48.4375 Generator accuracy: 93.75\n",
            "3900 epoch Discriminator accuracy: 51.5625 Generator accuracy: 90.625\n",
            "4000 epoch Discriminator accuracy: 50.0 Generator accuracy: 96.875\n",
            "4100 epoch Discriminator accuracy: 65.625 Generator accuracy: 90.625\n",
            "4200 epoch Discriminator accuracy: 50.0 Generator accuracy: 87.5\n",
            "4300 epoch Discriminator accuracy: 48.4375 Generator accuracy: 87.5\n",
            "4400 epoch Discriminator accuracy: 28.125 Generator accuracy: 100.0\n",
            "4500 epoch Discriminator accuracy: 46.875 Generator accuracy: 96.875\n",
            "4600 epoch Discriminator accuracy: 56.25 Generator accuracy: 87.5\n",
            "4700 epoch Discriminator accuracy: 51.5625 Generator accuracy: 90.625\n",
            "4800 epoch Discriminator accuracy: 42.1875 Generator accuracy: 90.625\n",
            "4900 epoch Discriminator accuracy: 54.6875 Generator accuracy: 90.625\n",
            "5000 epoch Discriminator accuracy: 17.1875 Generator accuracy: 100.0\n",
            "5100 epoch Discriminator accuracy: 46.875 Generator accuracy: 90.625\n",
            "5200 epoch Discriminator accuracy: 89.0625 Generator accuracy: 90.625\n",
            "5300 epoch Discriminator accuracy: 45.3125 Generator accuracy: 93.75\n",
            "5400 epoch Discriminator accuracy: 45.3125 Generator accuracy: 93.75\n",
            "5500 epoch Discriminator accuracy: 51.5625 Generator accuracy: 90.625\n",
            "5600 epoch Discriminator accuracy: 65.625 Generator accuracy: 90.625\n",
            "5700 epoch Discriminator accuracy: 51.5625 Generator accuracy: 96.875\n",
            "5800 epoch Discriminator accuracy: 48.4375 Generator accuracy: 90.625\n",
            "5900 epoch Discriminator accuracy: 50.0 Generator accuracy: 84.375\n",
            "6000 epoch Discriminator accuracy: 92.1875 Generator accuracy: 93.75\n",
            "6100 epoch Discriminator accuracy: 73.4375 Generator accuracy: 90.625\n",
            "6200 epoch Discriminator accuracy: 48.4375 Generator accuracy: 93.75\n",
            "6300 epoch Discriminator accuracy: 70.3125 Generator accuracy: 90.625\n",
            "6400 epoch Discriminator accuracy: 51.5625 Generator accuracy: 93.75\n",
            "6500 epoch Discriminator accuracy: 96.875 Generator accuracy: 96.875\n",
            "6600 epoch Discriminator accuracy: 51.5625 Generator accuracy: 87.5\n",
            "6700 epoch Discriminator accuracy: 35.9375 Generator accuracy: 93.75\n",
            "6800 epoch Discriminator accuracy: 76.5625 Generator accuracy: 90.625\n",
            "6900 epoch Discriminator accuracy: 46.875 Generator accuracy: 96.875\n",
            "7000 epoch Discriminator accuracy: 37.5 Generator accuracy: 100.0\n",
            "7100 epoch Discriminator accuracy: 48.4375 Generator accuracy: 90.625\n",
            "7200 epoch Discriminator accuracy: 70.3125 Generator accuracy: 90.625\n",
            "7300 epoch Discriminator accuracy: 65.625 Generator accuracy: 96.875\n",
            "7400 epoch Discriminator accuracy: 50.0 Generator accuracy: 84.375\n",
            "7500 epoch Discriminator accuracy: 40.625 Generator accuracy: 100.0\n",
            "7600 epoch Discriminator accuracy: 50.0 Generator accuracy: 93.75\n",
            "7700 epoch Discriminator accuracy: 51.5625 Generator accuracy: 96.875\n",
            "7800 epoch Discriminator accuracy: 59.375 Generator accuracy: 93.75\n",
            "7900 epoch Discriminator accuracy: 46.875 Generator accuracy: 90.625\n",
            "8000 epoch Discriminator accuracy: 64.0625 Generator accuracy: 93.75\n",
            "8100 epoch Discriminator accuracy: 51.5625 Generator accuracy: 87.5\n",
            "8200 epoch Discriminator accuracy: 50.0 Generator accuracy: 96.875\n",
            "8300 epoch Discriminator accuracy: 46.875 Generator accuracy: 87.5\n",
            "8400 epoch Discriminator accuracy: 34.375 Generator accuracy: 90.625\n",
            "8500 epoch Discriminator accuracy: 46.875 Generator accuracy: 84.375\n",
            "8600 epoch Discriminator accuracy: 48.4375 Generator accuracy: 93.75\n",
            "8700 epoch Discriminator accuracy: 73.4375 Generator accuracy: 100.0\n",
            "8800 epoch Discriminator accuracy: 75.0 Generator accuracy: 93.75\n",
            "8900 epoch Discriminator accuracy: 53.125 Generator accuracy: 90.625\n",
            "9000 epoch Discriminator accuracy: 93.75 Generator accuracy: 100.0\n",
            "9100 epoch Discriminator accuracy: 48.4375 Generator accuracy: 96.875\n",
            "9200 epoch Discriminator accuracy: 60.9375 Generator accuracy: 93.75\n",
            "9300 epoch Discriminator accuracy: 29.6875 Generator accuracy: 93.75\n",
            "9400 epoch Discriminator accuracy: 50.0 Generator accuracy: 100.0\n",
            "9500 epoch Discriminator accuracy: 82.8125 Generator accuracy: 100.0\n",
            "9600 epoch Discriminator accuracy: 50.0 Generator accuracy: 96.875\n",
            "9700 epoch Discriminator accuracy: 45.3125 Generator accuracy: 90.625\n",
            "9800 epoch Discriminator accuracy: 98.4375 Generator accuracy: 93.75\n",
            "9900 epoch Discriminator accuracy: 50.0 Generator accuracy: 93.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo2QU6PmTmOl"
      },
      "source": [
        "!cp -r /content/outputAll /content/drive/MyDrive/outputAll"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCDfaAPASMEN"
      },
      "source": [
        "discriminator.save('/content/drive/MyDrive/outputAll/discriminator.h5')\r\n",
        "generator.save('/content/drive/MyDrive/outputAll/generator.h5')\r\n",
        "combined.save('/content/drive/MyDrive/outputAll/combined.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwt7Fc2q_786",
        "outputId": "30ea346c-334f-4368-b904-3682669dda81"
      },
      "source": [
        "loaded_model = load_model('/content/drive/MyDrive/outputAll/combined.h5')\r\n",
        "result = loaded_model.summary()\r\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "Model: \"model_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_15 (InputLayer)        [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "model_13 (Functional)        (None, 128, 128, 3)       3376131   \n",
            "_________________________________________________________________\n",
            "model_12 (Functional)        (None, 1)                 1720385   \n",
            "=================================================================\n",
            "Total params: 5,096,516\n",
            "Trainable params: 5,092,036\n",
            "Non-trainable params: 4,480\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6MiFRSExaKz",
        "outputId": "12b6a097-9bd4-4e9a-af57-9d36e8f6f0f1"
      },
      "source": [
        "!ls /content/drive/MyDrive/outputAll/ | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}